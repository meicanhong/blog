(window.webpackJsonp=window.webpackJsonp||[]).push([[44],{485:function(t,s,a){"use strict";a.r(s);var n=a(2),p=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"how-to-build-a-more-fast-and-stable-crawler"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#how-to-build-a-more-fast-and-stable-crawler"}},[t._v("#")]),t._v(" How to build a more fast and stable crawler")]),t._v(" "),s("h2",{attrs:{id:"_1-不要重复造轮子"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-不要重复造轮子"}},[t._v("#")]),t._v(" #1 不要重复造轮子")]),t._v(" "),s("p",[t._v("RSSHub 是一个开源的 RSS 订阅服务，有很多开发者在上面开发了各种各样的订阅源，比如：")]),t._v(" "),s("ul",[s("li",[t._v("twitter")]),t._v(" "),s("li",[t._v("youtube")]),t._v(" "),s("li",[t._v("知乎")]),t._v(" "),s("li",[t._v("豆瓣")]),t._v(" "),s("li",[t._v("等等")])]),t._v(" "),s("p",[t._v("这些都是高质量的数据源，如果自己从头开始写，不仅浪费时间，而且质量还可能不如这些现成的。我们只需要写程序去接收统一的 RSS 订阅源返回的数据，然后进行处理，就可以快速获取各个平台的数据。")]),t._v(" "),s("p",[t._v("拿Twitter举例，我们只需要提供 Twitter Cookie 配置到 RSSHub 中，访问 RSSHub 的 API "),s("code",[t._v("http://localhost:1200/twitter/user/yihui_indie")]),t._v(" 就可以获取到 Twitter 用户 yihui_indie 的推文。")]),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[t._v("<item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("\n<title"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("Re @boo_hz 哈哈哈，其实是有的。但管他呢😬</title"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("\n<description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("Re @boo_hz 哈哈哈，其实是有的。但管他呢😬</description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("\n<link"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("https"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//x.com/yihui_indie/status/1870409487733149905</link"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v('\n<guid isPermaLink="false"'),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("https"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//twitter.com/yihui_indie/status/1870409487733149905</guid"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("\n<pubDate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("Sat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" 21 Dec 2024 10"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("02"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("27 GMT</pubDate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("\n<author"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("熠辉 Indie</author"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("\n</item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("\n\n<item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("\n<title"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("Re @hixiaoji 估计也是你收到产品建议最多的一条动态吧🤣</title"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("\n<description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("Re @hixiaoji 估计也是你收到产品建议最多的一条动态吧🤣</description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("\n<link"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("https"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//x.com/yihui_indie/status/1870335626970866059</link"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v('\n<guid isPermaLink="false"'),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("https"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//twitter.com/yihui_indie/status/1870335626970866059</guid"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("\n<pubDate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("Sat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" 21 Dec 2024 05"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("08"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("57 GMT</pubDate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("\n<author"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("熠辉 Indie</author"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("\n</item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v("\n")])])]),s("h2",{attrs:{id:"_2-借助llm完成数据处理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-借助llm完成数据处理"}},[t._v("#")]),t._v(" #2 借助LLM完成数据处理")]),t._v(" "),s("p",[t._v("我们获取一个平台的数据内容，通常需要对齐平台进行特制化处理，比如：")]),t._v(" "),s("ul",[s("li",[t._v("招聘平台需要提取出职位名称、职位链接、职位发布时间、职位公司、职位地点、职位薪资、职位要求等")]),t._v(" "),s("li",[t._v("知乎需要提取出回答内容、回答链接、回答发布时间、回答作者、回答点赞数、回答评论数等")]),t._v(" "),s("li",[t._v("等等")])]),t._v(" "),s("p",[t._v("一般情况下，我们可以通过 browserless 很轻松可以获取网页的源数据(包裹HTML的数据内容)，然后通过 bs4 去除里面无用的标签，可以获得一份干净简短的HTML数据。这时候我们可以将这份数据交给LLM，让LLM从中提取出我们预期的 struct 数据。")]),t._v(" "),s("p",[t._v("举例：我想要获取 https://gmgn.ai/trade?chain=sol&tab=smart_degen 的聪明钱数据，我会利用 firecrawl 的 crawl api 完成这个任务")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("GmgnTokenInfo")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("BaseModel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v("\n    volume"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v("\n    holders"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v("\n    volume_1h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v("\n    price"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v("\n\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("GmgnTokenInfoList")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("BaseModel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    tokens"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("GmgnTokenInfo"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("crawl_gmgn")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    app "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" firecrawl_app"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" app"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scrape_url"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"https://gmgn.ai/?chain=sol"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'formats'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'extract'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'extract'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'schema'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" GmgnTokenInfoList"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model_json_schema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("json"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dumps"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" indent"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("输出")]),t._v(" "),s("div",{staticClass:"language-json extra-class"},[s("pre",{pre:!0,attrs:{class:"language-json"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"tokens"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"GOBLY"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"volume"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"$6.3K"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"holders"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"28,202"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"volume_1h"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"7.3K"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"price"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"$0.0\\u20856389"')]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"USACOIN"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"volume"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"$11.4M"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"holders"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"21,530"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"volume_1h"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"472.1K"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"price"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"$0.0114"')]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            ...\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("这里我用到了 firecrawl 工具，这是一个很强大的爬虫工具，它可以获取任意网页的数据内容，这里我们使用它的 extract 功能，将 "),s("code",[t._v("GmgnTokenInfoList")]),t._v(" 的结构丢给它，firecrwal 背后其实是调用 LLM 完成数据提取。")]),t._v(" "),s("p",[t._v("firecrawl scrape 详情可以参考：https://docs.firecrawl.dev/v1-welcome#extract-format")])])}),[],!1,null,null,null);s.default=p.exports}}]);