(window.webpackJsonp=window.webpackJsonp||[]).push([[46],{488:function(v,e,a){"use strict";a.r(e);var _=a(2),t=Object(_.a)({},(function(){var v=this,e=v._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[e("h1",{attrs:{id:"rag-架构进化-从-已死-争议到-8-种实战路径"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#rag-架构进化-从-已死-争议到-8-种实战路径"}},[v._v("#")]),v._v(' RAG 架构进化：从"已死"争议到 8 种实战路径')]),v._v(" "),e("p",[v._v("前阵子 Hacker News 上一篇《RAG 讣告：被智能体杀死，被上下文窗口埋葬》的文章炸翻了天，200 多个点赞，近 200 条评论。作者核心观点很直接：Claude 都有 200K token 了，Agent 用个 grep 就能检索，还要 RAG 干什么？")]),v._v(" "),e("p",[v._v("说实话，看完这篇文章我第一反应是——这事儿没那么简单。")]),v._v(" "),e("h2",{attrs:{id:"争议背后的盲区"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#争议背后的盲区"}},[v._v("#")]),v._v(" 争议背后的盲区")]),v._v(" "),e("p",[v._v('评论区里有人立马反驳：grep 在几千个文件里找代码确实好使，但你见过企业级知识库动辄几百万份文档吗？这时候 grep 就成了大海捞针。更重要的是，grep 精确匹配"供应链风险"三个字，永远找不到讨论"采购链依赖"的文档。语义理解和精确匹配不是替代关系，是互补关系。')]),v._v(" "),e("p",[v._v("还有一个容易被混淆的点：Agentic RAG 不是 RAG 的替代品，它就是 RAG 的一种形态。RAG 从来不是某个具体架构，而是一个原则——用检索来增强生成。至于怎么检索、什么时候检索，那是实现细节。")]),v._v(" "),e("p",[v._v('所以"RAG 已死"这个论调，存在三个典型盲区：')]),v._v(" "),e("p",[e("strong",[v._v("成本和规模盲区")]),v._v('：200K token 听着很多，但也就 15 万字左右。企业知识库几百万份文档，全塞进 prompt 成本不可接受，而且上下文过长会出现"Lost in the Middle"现象——中间信息模型压根记不住。')]),v._v(" "),e("p",[e("strong",[v._v("语义理解盲区")]),v._v("：grep 的精确匹配在专业术语上很强，但语义查询是它的软肋。现在生产环境主流做法是混合检索（BM25 + 向量 + 重排序），两者各司其职。")]),v._v(" "),e("p",[e("strong",[v._v("概念混淆盲区")]),v._v("：把 Agentic Search 当成 RAG 的替代是错的。Agentic RAG 本身就是 RAG 进化的一种形态，就像从骑自行车变成了开自动驾驶汽车，本质还是交通工具，但智能化程度完全不同。")]),v._v(" "),e("h2",{attrs:{id:"_8-种架构-一条进化路径-不是选择题"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_8-种架构-一条进化路径-不是选择题"}},[v._v("#")]),v._v(" 8 种架构：一条进化路径，不是选择题")]),v._v(" "),e("p",[v._v('很多人把 8 种 RAG 架构当成选择题来纠结，其实这更像是一条进化路径。核心问题只有一个：你的检索系统需要多少"智能"？')]),v._v(" "),e("h3",{attrs:{id:"naive-rag-起点-也是基础"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#naive-rag-起点-也是基础"}},[v._v("#")]),v._v(" Naive RAG：起点，也是基础")]),v._v(" "),e("p",[v._v("流程像自来水管一样直白：文档切块 → 向量化 → 存入向量数据库 → 用户提问时检索相似块 → 喂给大模型生成答案。")]),v._v(" "),e("p",[v._v('这个架构的问题很明显：检索结果不一定对，但大模型不会质疑，拿来就用。检索错了、文档不相关、或者截断位置不合适，这些缺陷都会直接影响最终答案。更糟糕的是，当检索质量很差时，大模型会开始"创造性编造"，产生幻觉。')]),v._v(" "),e("p",[v._v("不过别嫌弃它简单。很多团队一开始就上 Graph 或 Agentic，结果出问题连瓶颈在哪都找不到。正确的做法是先跑通 Naive RAG，收集真实反馈，再针对性升级。")]),v._v(" "),e("p",[v._v("实际实现时，你需要注意几个关键点：切块大小很重要，通常 512-1024 token 比较合适；重叠部分不能少，否则语义容易断开；向量数据库的选择也很有讲究，Milvus、Weaviate、Pinecone 各有优劣。")]),v._v(" "),e("h3",{attrs:{id:"corrective-rag-加入质量控制"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#corrective-rag-加入质量控制"}},[v._v("#")]),v._v(" Corrective RAG：加入质量控制")]),v._v(" "),e("p",[v._v('在 Naive 基础上加个"质检员"，这就是 Corrective RAG 的核心思想。系统会评估每个检索结果的质量，然后做三件事：相关的直接用，不相关的扔掉，模糊的精炼后再用。')]),v._v(" "),e("p",[v._v("具体实现上，它引入了一个检索评估器（Retrieve Evaluator），对检索结果打分。如果分数高，说明检索质量好，直接进入生成环节；如果分数低，说明检索失败，系统会触发回退机制——要么重新查询，要么调用外部搜索引擎（比如 Google、Bing API）补充信息。")]),v._v(" "),e("p",[v._v("这个架构在法律研究、合规审查这些高风险场景特别有用。试想一下，用户问一个法律条款的适用范围，Naive RAG 可能检索到错误的法律文件，导致错误答案。Corrective RAG 会先评估检索结果，发现相关性不够时主动去权威法律网站检索，确保答案准确。")]),v._v(" "),e("p",[v._v("实现上可以用 LangChain 的 CRAG 模块，或者自己写一个评估器。关键在于评估标准的设计——相关性阈值设多少合适？回退机制触发几次？这些都需要根据实际业务调优。")]),v._v(" "),e("h3",{attrs:{id:"self-rag-让模型学会反思"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#self-rag-让模型学会反思"}},[v._v("#")]),v._v(" Self RAG：让模型学会反思")]),v._v(" "),e("p",[v._v("Self RAG 来自 2023 年的一篇论文，核心思想是让模型在生成过程中不断反思自己。模型会自我反思四个问题：需要检索吗？文档相关吗？答案有支撑吗？答案有用吗？")]),v._v(" "),e("p",[v._v('具体实现上，它引入了特殊的"反思 token"：'),e("code",[v._v("IsRel")]),v._v("（文档相关吗？）、"),e("code",[v._v("IsSup")]),v._v("（答案有支撑吗？）、"),e("code",[v._v("IsUse")]),v._v("（答案有用吗？）。每个环节都有这些 token 打分，质量不达标就重来。比如检索到的文档相关性低，模型会触发 "),e("code",[v._v("IsRel:No")]),v._v(" 标记，然后重新检索；生成的答案没有文档支撑，会触发 "),e("code",[v._v("IsSup:No")]),v._v("，然后重新生成。")]),v._v(" "),e("p",[v._v('从"无脑流水线"到"有自我意识的系统"，这是 RAG 智能化的重要一步。根据研究数据，Self RAG 能降低 40-60% 的幻觉率，在需要高准确性的场景效果显著。')]),v._v(" "),e("p",[v._v("代价是成本变高，生成速度变慢。毕竟每个环节都要打分、可能还要重来。如果你的场景容错率高、成本敏感，Naive RAG 可能更合适；如果是医疗诊断、金融分析这些高风险场景，Self RAG 的额外成本是值得的。")]),v._v(" "),e("p",[v._v("训练 Self RAG 需要专门的标注数据——不是标注答案，而是标注反思 token 的正确性。这比标注答案更难，因为需要专家对每个环节的质量做判断。所以实际应用中，很多人会用现成的 Self RAG 模型，或者用提示词工程模拟反思过程。")]),v._v(" "),e("h3",{attrs:{id:"multi-head-rag-多视角并行检索"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#multi-head-rag-多视角并行检索"}},[v._v("#")]),v._v(" Multi-Head RAG：多视角并行检索")]),v._v(" "),e("p",[v._v('借鉴 Transformer 的多头注意力机制，Multi-Head RAG 对同一个问题用不同"视角"理解，并行检索后融合结果。')]),v._v(" "),e("p",[v._v('举个例子，用户问"苹果最近的表现如何"。Naive RAG 可能只往一个方向检索，要么是科技公司要么是水果。Multi-Head RAG 会同时发起多个查询：一个是"苹果公司的股价表现"，一个是"苹果公司的产品销量"，还有一个可能是"苹果水果的价格走势"。最后根据上下文或者用户历史行为，判断用户真正想要什么。')]),v._v(" "),e("p",[v._v("实现上，可以用查询改写（Query Rewriting）或者查询扩展（Query Expansion）技术。LlamaIndex 的 Multi-Vector Retriever、LangChain 的 MultiQuery Retriever 都能实现类似效果。")]),v._v(" "),e("p",[v._v('这个架构解决了单一角度的盲区问题，适合查询意图模糊的场景。比如用户问"如何优化性能"，是数据库性能、前端性能、还是算法性能？Multi-Head RAG 会把各种可能性都检索一遍，然后融合结果。')]),v._v(" "),e("p",[v._v("当然，延迟和成本都会上升。三个并发查询意味着三倍的检索成本，融合结果也需要额外的推理步骤。如果你的查询场景意图明确（比如客服系统，用户问题通常很具体），Naive RAG 可能更高效；如果是开放域问答、知识探索，Multi-Head RAG 会更合适。")]),v._v(" "),e("h3",{attrs:{id:"graph-rag-知识图谱加持"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#graph-rag-知识图谱加持"}},[v._v("#")]),v._v(" Graph RAG：知识图谱加持")]),v._v(" "),e("p",[v._v('Graph RAG 不再只是找相似文本块，而是理解文本块之间的关系。用户问"ABC 公司的领导层有谁"，Naive RAG 可能检索到一篇提到 CEO 的文档，但遗漏了其他高管。Graph RAG 会在知识图谱里遍历实体关系，精准定位所有领导层成员。')]),v._v(" "),e("p",[v._v('核心思想是先把非结构化文本转化为结构化知识图谱：实体（人名、公司名、事件）作为节点，关系（属于、领导、投资）作为边。检索时不再是"找相似文本"，而是"在图谱上推理"。')]),v._v(" "),e("p",[v._v('Microsoft Research 在 2024 年发布的 GraphRAG 用 Leiden 算法做层次社区检测，在大规模查询（约 100 万 tokens）上表现卓越。它把文档按照语义聚合成不同的"社区"，每个社区有自己的摘要和主题。用户问全局问题时（比如"整个行业的主要趋势是什么"），它能在社区层面推理，而不是纠结于单个文档碎片。')]),v._v(" "),e("p",[v._v("构建知识图谱是 Graph RAG 的最大挑战。需要从文本中抽取实体和关系，这本身就是一个 NLP 难题。LLaMA、GPT 这些模型可以用来做实体抽取，但准确率很难保证，尤其是专业领域的实体识别（比如医疗术语、法律概念）。而且知识图谱更新困难——新增一个文档，可能要重新抽取、重新链接、重新计算社区结构。")]),v._v(" "),e("p",[v._v("所以 Graph RAG 适合知识结构稳定、更新频率低的场景，比如历史研究、企业知识库。如果你的数据每天都在变（比如新闻、社交媒体），构建和维护知识图谱的成本可能超过收益。")]),v._v(" "),e("h3",{attrs:{id:"agentic-rag-从管道到智能体"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#agentic-rag-从管道到智能体"}},[v._v("#")]),v._v(" Agentic RAG：从管道到智能体")]),v._v(" "),e("p",[v._v("这是当前最前沿的形态，也是争议最大的地方。系统从被动管道变成主动智能体，能分解复杂问题、选择合适工具、迭代检索推理，直到满意为止。")]),v._v(" "),e("p",[v._v('举个具体例子。用户问"我们公司去年在云服务上的支出是多少，今年能优化多少"。Naive RAG 可能检索几篇关于云成本优化的文档，然后给出一个泛泛的建议。Agentic RAG 会这样处理：')]),v._v(" "),e("ol",[e("li",[v._v("分解问题：支出查询 + 优化分析")]),v._v(" "),e("li",[v._v("支出查询：选择 SQL 工具，查询财务数据库")]),v._v(" "),e("li",[v._v("优化分析：检索云成本优化文档，结合当前支出结构分析")]),v._v(" "),e("li",[v._v("可能还需要调用 Calculator 计算优化比例")]),v._v(" "),e("li",[v._v("最终综合所有信息，给出具体答案")])]),v._v(" "),e("p",[v._v('LlamaIndex 有句名言："Naive RAG 已死，智能体检索万岁"。关键不是检索不检索，而是谁来决定何时检索、检索什么、用什么工具检索。')]),v._v(" "),e("p",[v._v("Agentic RAG 的核心组件包括：规划器（Planner，分解问题）、工具集（Tools，SQL、API、搜索引擎）、执行器（Executor，按计划执行）、反思器（Reflector，评估结果质量）。这些组件可以用 LangChain 的 Agent 框架、AutoGPT、或者自己编排。")]),v._v(" "),e("p",[v._v("当然，代价也很明显：延迟高、不可预测、成本高。一个复杂问题可能触发十几次工具调用，每次都是一次推理成本。而且 Agent 的行为很难预测——它会选择什么工具？会迭代几次？这些都不像 Naive RAG 那样可控。")]),v._v(" "),e("p",[v._v('所以 Agentic RAG 适合复杂任务编排、多工具协作的场景。如果你的问题是简单问答（比如"年假政策是什么"），Naive RAG 足够了；如果需要多步推理、动态决策，Agentic RAG 的价值才体现出来。')]),v._v(" "),e("h3",{attrs:{id:"adaptive-rag-自适应策略"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#adaptive-rag-自适应策略"}},[v._v("#")]),v._v(" Adaptive RAG：自适应策略")]),v._v(" "),e("p",[v._v('Adaptive RAG 的核心是"路由比架构更重要"。不是所有问题都需要检索，简单查询直接用 LLM 反而更快更便宜。')]),v._v(" "),e("p",[v._v('根据问题类型动态调整策略：简单事实问题（比如"公司地址在哪"）直接回答；多步推理问题（比如"为什么上季度营收下降"）迭代检索；开放问题（比如"帮我写个行业分析"）多轮检索扩展加创造性生成。')]),v._v(" "),e("p",[v._v("实现上，Adaptive RAG 有一个路由器（Router），先分析问题类型，然后选择合适的处理策略。路由器本身可以是一个分类模型，或者用 LLM 做意图识别。LlamaIndex 的 Router Retriever、LangChain 的 Agent Executor 都能实现类似效果。")]),v._v(" "),e("p",[v._v('这个架构的优势是成本优化。简单问题跳过检索，直接用 LLM 的内置知识，节省了向量检索的延迟和成本。复杂问题才启动完整流程，避免"大炮打蚊子"。')]),v._v(" "),e("p",[v._v("实际应用中，路由策略的设计很关键。路由太敏感，所有问题都走检索，成本下不来；路由太迟钝，该检索的不检索，答案质量下降。需要根据实际业务数据调优，监控不同路由的准确率和成本。")]),v._v(" "),e("h3",{attrs:{id:"sfr-rag-工业级封装"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sfr-rag-工业级封装"}},[v._v("#")]),v._v(" SFR RAG：工业级封装")]),v._v(" "),e("p",[v._v("SFR RAG（Sophisticated Fine-tuned RAG）把各种技术组件打包成工业级方案，整合了高质量 embedding、重排序、上下文压缩、引用生成、质量验证等最佳实践。")]),v._v(" "),e("p",[v._v("高质量 embedding 是基础。OpenAI 的 text-embedding-3、Cohere 的 embed、或者自己 fine-tune 的领域 embedding，直接影响检索质量。通用 embedding 在专业领域表现差，比如医疗、法律，用领域数据 fine-tune 能显著提升效果。")]),v._v(" "),e("p",[v._v("重排序（Reranking）是关键。初次检索可能召回 100 个结果，但只有前几个真正相关。重排序模型（比如 Cohere Rerank、BGE Reranker）会对这 100 个结果重新打分，选出最相关的 5-10 个。生产数据显示，重排序能提升 15-30% 的检索准确率。")]),v._v(" "),e("p",[v._v('上下文压缩（Context Compression）解决"噪音太多"的问题。检索到的文档可能很长，只有一小段真正相关。压缩模块会提取相关片段，去掉冗余信息，既节省 token 又提升质量。')]),v._v(" "),e("p",[v._v('引用生成（Citation）是信任的基础。答案要标明来源，用户才能验证。SFR RAG 会自动生成引用链接，比如"根据《员工手册》第三章第二节"。这在法律、医疗、金融这些需要可追溯性的场景尤其重要。')]),v._v(" "),e("p",[v._v("质量验证（Quality Check）是最后一步。生成答案后，系统会自动检查：答案是否回应了问题？是否有文档支撑？逻辑是否自洽？质量不达标的答案会被拦截或要求重新生成。")]),v._v(" "),e("p",[v._v("这些技术可以单独用，但组合起来效果最好。SFR RAG 就是把这些最佳实践打包成一个端到端的系统，适合不想重复造轮子的团队。LangChain、LlamaIndex 都有现成的 SFR 实现，或者用 LangSmith、DeepEval 这些工具搭建自己的质量验证体系。")]),v._v(" "),e("h2",{attrs:{id:"两个进化维度"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#两个进化维度"}},[v._v("#")]),v._v(" 两个进化维度")]),v._v(" "),e("p",[v._v("看完整条路径，你会发现 RAG 的进化其实沿着两个维度：")]),v._v(" "),e("p",[e("strong",[v._v("系统智能度")]),v._v("：从无脑执行 → 质量控制 → 自我反思 → 自由决策")]),v._v(" "),e("p",[e("strong",[v._v("知识结构复杂度")]),v._v("：从简单文本块 → 多视角融合 → 知识图谱 → 智能体协作")]),v._v(" "),e("p",[v._v("选型的时候问自己四个问题：知识库多大？问题多复杂？容错空间多大？预算多少？答案自然就出来了。")]),v._v(" "),e("h2",{attrs:{id:"实践中的三个坑"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#实践中的三个坑"}},[v._v("#")]),v._v(" 实践中的三个坑")]),v._v(" "),e("p",[v._v("聊完架构，说点实战经验。")]),v._v(" "),e("p",[e("strong",[v._v("坑一：过度工程化")])]),v._v(" "),e("p",[v._v("很多团队一开始就上 GraphRAG 或 Agentic 多模态，结果发现问题都找不到在哪。正确的做法是先跑通 Naive RAG，收集真实业务问题作为评测基准，每个新架构上线前都用这些问题盲评打分。这比看任何公开 Benchmark 都有用。")]),v._v(" "),e("p",[e("strong",[v._v("坑二：忽视检索质量")])]),v._v(" "),e("p",[v._v("检索是 RAG 的天花板，生成只是在天花板下装修。如果检索系统没拿到准确文档，再好的提示词工程也救不了。生产环境推荐混合检索（BM25 + 向量 + 重排序），能提升 15-25% 的准确率。")]),v._v(" "),e("p",[e("strong",[v._v("坑三：缺少评测体系")])]),v._v(" "),e("p",[v._v("准备 10-20 个真实业务问题，定期用这些问题测试系统表现。没有评测体系，失败只在用户投诉时暴露，那时候就太晚了。")]),v._v(" "),e("h2",{attrs:{id:"总结"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),e("p",[v._v("RAG 不是死了，是进化了。Naive RAG 确实在退出舞台，但 Agentic Retrieval 才刚开始。")]),v._v(" "),e("p",[v._v("记住三点：先跑通基础流程再逐步加料，关注检索质量而不是生成技巧，建立自己的评测体系。")]),v._v(" "),e("p",[v._v("架构选择没有银弹，关键是理解问题本质。大多数业务问题用 Basic RAG 或 Two-Step RAG 就能解决，别被潮流带着跑。实现价值，而非实现潮流。")])])}),[],!1,null,null,null);e.default=t.exports}}]);